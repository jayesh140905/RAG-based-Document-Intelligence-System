{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14627818,"sourceType":"datasetVersion","datasetId":9343902}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q pymupdf pdfplumber sentence-transformers faiss-cpu tiktoken\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T15:05:19.221183Z","iopub.execute_input":"2026-01-29T15:05:19.221365Z","iopub.status.idle":"2026-01-29T15:05:27.678594Z","shell.execute_reply.started":"2026-01-29T15:05:19.221340Z","shell.execute_reply":"2026-01-29T15:05:27.677733Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ================================\n# Gen-AI PDF Summarizer (NotebookLM-inspired)\n# Environment Setup Cell\n# ================================\n\n# Core\nimport os\nimport re\nimport json\nimport math\nfrom typing import List, Dict\n\n# Data handling\nimport numpy as np\nimport pandas as pd\n\n# PDF processing\nimport fitz  # PyMuPDF\nimport pdfplumber\n\n# NLP & Embeddings\nfrom sentence_transformers import SentenceTransformer\n\n# Vector Search\nimport faiss\n\n# Token counting (important for chunking)\nimport tiktoken\n\n# LLM API (choose ONE later)\n# import openai\n# from transformers import pipeline\n\n# Visualization / Debug\nfrom tqdm import tqdm\nfrom pprint import pprint\n\nprint(\"âœ… Environment setup complete\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-29T15:05:27.680680Z","iopub.execute_input":"2026-01-29T15:05:27.681049Z","iopub.status.idle":"2026-01-29T15:05:56.652741Z","shell.execute_reply.started":"2026-01-29T15:05:27.681019Z","shell.execute_reply":"2026-01-29T15:05:56.651935Z"}},"outputs":[{"name":"stderr","text":"2026-01-29 15:05:40.497320: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1769699140.684576      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1769699140.739495      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1769699141.196588      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769699141.196623      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769699141.196625      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769699141.196628      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"âœ… Environment setup complete\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ================================\n# Improved Embeddings + Re-indexing\n# (BGE model + context prefix)\n# ================================\n\n# Stronger embedding model (much better for retrieval)\nembedding_model = SentenceTransformer(\n    \"BAAI/bge-base-en-v1.5\"\n)\n\nprint(\"âœ… BGE embedding model loaded\")\n\n# BGE requires query & passage prefixes\nPASSAGE_PREFIX = \"Represent this passage for retrieval: \"\nQUERY_PREFIX = \"Represent this question for retrieving relevant passages: \"\n\n# Prepare texts WITH context prefix\ntexts = []\nfor chunk in chunks:\n    contextual_text = (\n        f\"Page {chunk['page']}. \"\n        + chunk[\"text\"].strip()\n    )\n    texts.append(PASSAGE_PREFIX + contextual_text)\n\n# Generate embeddings\nembeddings = embedding_model.encode(\n    texts,\n    show_progress_bar=True,\n    convert_to_numpy=True,\n    normalize_embeddings=True\n)\n\nprint(f\"âœ… Generated embeddings with shape: {embeddings.shape}\")\n\n# Rebuild FAISS index\nembedding_dim = embeddings.shape[1]\nindex = faiss.IndexFlatIP(embedding_dim)\nindex.add(embeddings)\n\nprint(f\"âœ… FAISS index rebuilt with {index.ntotal} vectors\")\n\n# Keep metadata aligned\nchunk_metadata = chunks\n\n# Sanity check\nprint(\"\\nğŸ” Sample embedded passage:\\n\")\nprint(texts[0][:300], \"...\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T15:05:56.653725Z","iopub.execute_input":"2026-01-29T15:05:56.654284Z","iopub.status.idle":"2026-01-29T15:06:00.523386Z","shell.execute_reply.started":"2026-01-29T15:05:56.654259Z","shell.execute_reply":"2026-01-29T15:06:00.522370Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f98fbda3bfa4dc28f7521727d8457b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3c63ac334a34b0cb070242d9217c0ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c06ca09245e4d6d838c5181396a7759"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f07a92fcd9714f47b5c97e3a8b595adf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/777 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"308684c4433847a1b84e06f64e1db17d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4481c48f45e45be917dc6b53374ef71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93a5ec1b0c8948a4943f22c5e0477de6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7513a4eefab47b88297753ad09c47ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76cdf3f543154825ba6c1ae2e05ef1a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5f3b2bdf9f841cc9ce88c1193b93e2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed11dafa111349d0a813e5b6c43e9db9"}},"metadata":{}},{"name":"stdout","text":"âœ… BGE embedding model loaded\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/580696478.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Prepare texts WITH context prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     contextual_text = (\n\u001b[1;32m     21\u001b[0m         \u001b[0;34mf\"Page {chunk['page']}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'chunks' is not defined"],"ename":"NameError","evalue":"name 'chunks' is not defined","output_type":"error"}],"execution_count":3},{"cell_type":"code","source":"# ================================\n# PDF Loading & Basic Inspection\n# ================================\n\n# Update this to your dataset folder name if needed\nDATA_DIR = \"/kaggle/input\"\n\n# Find the first PDF in the input directory\npdf_path = None\nfor root, dirs, files in os.walk(DATA_DIR):\n    for file in files:\n        if file.lower().endswith(\".pdf\"):\n            pdf_path = os.path.join(root, file)\n            break\n    if pdf_path:\n        break\n\nif pdf_path is None:\n    raise FileNotFoundError(\"âŒ No PDF file found in /kaggle/input\")\n\nprint(f\"ğŸ“„ PDF found at: {pdf_path}\")\n\n# Open PDF\ndoc = fitz.open(pdf_path)\n\nprint(f\"âœ… PDF loaded successfully\")\nprint(f\"ğŸ“‘ Total pages: {doc.page_count}\")\n\n# Preview text from first page\nfirst_page = doc.load_page(0)\npreview_text = first_page.get_text(\"text\")[:1000]\n\nprint(\"\\nğŸ” Preview of Page 1:\\n\")\nprint(preview_text if preview_text.strip() else \"[No extractable text found]\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T15:06:00.524326Z","iopub.status.idle":"2026-01-29T15:06:00.524719Z","shell.execute_reply.started":"2026-01-29T15:06:00.524521Z","shell.execute_reply":"2026-01-29T15:06:00.524551Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# Page-wise Text Extraction\n# ================================\n\ndef clean_text(text: str) -> str:\n    \"\"\"\n    Light text cleaning:\n    - Remove excessive newlines\n    - Remove repeated spaces\n    \"\"\"\n    text = re.sub(r'\\n{2,}', '\\n', text)\n    text = re.sub(r'[ \\t]{2,}', ' ', text)\n    return text.strip()\n\n\npages_data = []\n\nfor page_num in tqdm(range(doc.page_count), desc=\"Extracting pages\"):\n    page = doc.load_page(page_num)\n    text = page.get_text(\"text\")\n    \n    if text and text.strip():\n        cleaned_text = clean_text(text)\n    else:\n        cleaned_text = \"\"\n\n    pages_data.append({\n        \"page\": page_num + 1,   # 1-based indexing (human friendly)\n        \"text\": cleaned_text\n    })\n\nprint(f\"âœ… Extracted text from {len(pages_data)} pages\")\n\n# Show sample output\nprint(\"\\nğŸ” Sample extracted page data:\\n\")\npprint(pages_data[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T15:06:00.527404Z","iopub.status.idle":"2026-01-29T15:06:00.527870Z","shell.execute_reply.started":"2026-01-29T15:06:00.527638Z","shell.execute_reply":"2026-01-29T15:06:00.527669Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# Token-aware Text Chunking\n# ================================\n\n# Initialize tokenizer (OpenAI-style tokenization works well even for open-source models)\ntokenizer = tiktoken.get_encoding(\"cl100k_base\")\n\ndef count_tokens(text: str) -> int:\n    return len(tokenizer.encode(text))\n\n\ndef chunk_text(\n    text: str,\n    max_tokens: int = 700,\n    overlap: int = 100\n) -> List[str]:\n    \"\"\"\n    Splits text into overlapping token-based chunks.\n    \"\"\"\n    tokens = tokenizer.encode(text)\n    chunks = []\n\n    start = 0\n    while start < len(tokens):\n        end = start + max_tokens\n        chunk_tokens = tokens[start:end]\n        chunk_text = tokenizer.decode(chunk_tokens)\n        chunks.append(chunk_text)\n        start = end - overlap\n\n    return chunks\n\n\n# Create chunks with page metadata\nchunks = []\n\nfor page_data in tqdm(pages_data, desc=\"Chunking pages\"):\n    page_text = page_data[\"text\"]\n    \n    if not page_text:\n        continue\n\n    page_chunks = chunk_text(page_text)\n\n    for idx, chunk in enumerate(page_chunks):\n        chunks.append({\n            \"page\": page_data[\"page\"],\n            \"chunk_id\": f\"page_{page_data['page']}_chunk_{idx}\",\n            \"text\": chunk,\n            \"tokens\": count_tokens(chunk)\n        })\n\nprint(f\"âœ… Total chunks created: {len(chunks)}\")\n\n# Show sample chunk\nprint(\"\\nğŸ” Sample chunk:\\n\")\npprint(chunks[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T15:06:00.529397Z","iopub.status.idle":"2026-01-29T15:06:00.529837Z","shell.execute_reply.started":"2026-01-29T15:06:00.529605Z","shell.execute_reply":"2026-01-29T15:06:00.529633Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# Embeddings + FAISS Vector Index\n# ================================\n\n# Load embedding model (GPU will be used automatically if available)\nembedding_model = SentenceTransformer(\n    \"sentence-transformers/all-MiniLM-L6-v2\"\n)\n\nprint(\"âœ… Embedding model loaded\")\n\n# Prepare texts for embedding\ntexts = [chunk[\"text\"] for chunk in chunks]\n\n# Generate embeddings\nembeddings = embedding_model.encode(\n    texts,\n    show_progress_bar=True,\n    convert_to_numpy=True,\n    normalize_embeddings=True\n)\n\nprint(f\"âœ… Generated embeddings with shape: {embeddings.shape}\")\n\n# Create FAISS index\nembedding_dim = embeddings.shape[1]\nindex = faiss.IndexFlatIP(embedding_dim)  # Inner Product (cosine similarity with normalized vectors)\n\nindex.add(embeddings)\n\nprint(f\"âœ… FAISS index created with {index.ntotal} vectors\")\n\n# Keep metadata aligned with index positions\nchunk_metadata = chunks  # same order as embeddings\n\n# Sanity check\nprint(\"\\nğŸ” Sample metadata entry:\\n\")\npprint(chunk_metadata[0])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# Semantic Retrieval (RAG Step 1)\n# ================================\n\ndef retrieve_relevant_chunks(\n    question: str,\n    top_k: int = 5\n) -> List[Dict]:\n    \"\"\"\n    Retrieves top-k most relevant chunks for a given question.\n    \"\"\"\n    # Embed the question\n    question_embedding = embedding_model.encode(\n        [question],\n        convert_to_numpy=True,\n        normalize_embeddings=True\n    )\n\n    # Search FAISS index\n    scores, indices = index.search(question_embedding, top_k)\n\n    results = []\n    for score, idx in zip(scores[0], indices[0]):\n        chunk = chunk_metadata[idx]\n        results.append({\n            \"score\": float(score),\n            \"page\": chunk[\"page\"],\n            \"chunk_id\": chunk[\"chunk_id\"],\n            \"text\": chunk[\"text\"][:500] + \"...\"  # preview only\n        })\n\n    return results\n\n\n# -------------------------------\n# Test retrieval\n# -------------------------------\nsample_question = \"What methodology does the paper propose and how does it work?\"\n\n\nretrieved_chunks = retrieve_relevant_chunks(sample_question, top_k=5)\n\nprint(f\"\\nğŸ” Question: {sample_question}\\n\")\nfor i, res in enumerate(retrieved_chunks, 1):\n    print(f\"Result {i}\")\n    print(f\"  Score : {res['score']:.4f}\")\n    print(f\"  Page  : {res['page']}\")\n    print(f\"  Chunk : {res['chunk_id']}\")\n    print(f\"  Text  : {res['text']}\\n\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================\n# Two-Stage Retrieval + Re-ranking\n# ================================\n\ndef is_reference_chunk(text: str) -> bool:\n    text_lower = text.lower()\n\n    reference_signals = [\n        \"references\",\n        \"bibliography\",\n        \"proceedings of\",\n        \"doi:\",\n        \"pp.\",\n        \"et al.\",\n        \"association for computational linguistics\",\n        \"conference\",\n        \"journal\"\n    ]\n\n    # If many reference signals appear, it's likely a citation block\n    hits = sum(1 for sig in reference_signals if sig in text_lower)\n    return hits >= 2\n\n\nINTENT_KEYWORDS = [\n    \"method\", \"methodology\", \"approach\",\n    \"model\", \"architecture\", \"framework\",\n    \"proposed\", \"system\"\n]\n\ndef keyword_score(text: str) -> int:\n    text_lower = text.lower()\n    return sum(1 for kw in INTENT_KEYWORDS if kw in text_lower)\n\n\ndef retrieve_relevant_chunks_v2(\n    question: str,\n    stage1_k: int = 15,\n    final_k: int = 5,\n    min_score: float = 0.3\n):\n    \"\"\"\n    Two-stage retrieval:\n    1) Broad FAISS search\n    2) Re-rank using similarity + keyword + length heuristics\n    \"\"\"\n\n    # Embed question (BGE requires prefix)\n    question_embedding = embedding_model.encode(\n        [QUERY_PREFIX + question],\n        convert_to_numpy=True,\n        normalize_embeddings=True\n    )\n\n    # Stage 1: broad retrieval\n    scores, indices = index.search(question_embedding, stage1_k)\n\n    candidates = []\n    for score, idx in zip(scores[0], indices[0]):\n        if score < min_score:\n            continue\n\n        chunk = chunk_metadata[idx]\n        text = chunk[\"text\"]\n\n        if is_reference_chunk(text):\n            continue\n\n\n        candidates.append({\n            \"score\": float(score),\n            \"page\": chunk[\"page\"],\n            \"chunk_id\": chunk[\"chunk_id\"],\n            \"text\": text,\n            \"keyword_score\": keyword_score(text),\n            \"length\": len(text)\n        })\n\n    if not candidates:\n        return []\n\n    # Stage 2: re-ranking\n    candidates.sort(\n        key=lambda x: (\n            x[\"score\"],            # semantic similarity\n            x[\"keyword_score\"],    # intent alignment\n            x[\"length\"]            # prefer richer chunks\n        ),\n        reverse=True\n    )\n\n    return candidates[:final_k]\n\n\n# -------------------------------\n# Test improved retrieval\n# -------------------------------\ntest_question = \"What methodology does the paper propose and how does it work?\"\n\nresults = retrieve_relevant_chunks_v2(test_question)\n\nprint(f\"\\nğŸ” Question: {test_question}\\n\")\n\nif not results:\n    print(\"âŒ No strong matches found.\")\nelse:\n    for i, res in enumerate(results, 1):\n        print(f\"Result {i}\")\n        print(f\"  Score         : {res['score']:.4f}\")\n        print(f\"  Keyword score : {res['keyword_score']}\")\n        print(f\"  Page          : {res['page']}\")\n        print(f\"  Chunk         : {res['chunk_id']}\")\n        print(f\"  Text preview  : {res['text'][:500]}...\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T15:06:20.463068Z","iopub.execute_input":"2026-01-29T15:06:20.463625Z","iopub.status.idle":"2026-01-29T15:06:20.831126Z","shell.execute_reply.started":"2026-01-29T15:06:20.463598Z","shell.execute_reply":"2026-01-29T15:06:20.830136Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/844257937.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0mtest_question\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"What methodology does the paper propose and how does it work?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrieve_relevant_chunks_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_question\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nğŸ” Question: {test_question}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_55/844257937.py\u001b[0m in \u001b[0;36mretrieve_relevant_chunks_v2\u001b[0;34m(question, stage1_k, final_k, min_score)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# Stage 1: broad retrieval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage1_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'index' is not defined"],"ename":"NameError","evalue":"name 'index' is not defined","output_type":"error"}],"execution_count":4}]}